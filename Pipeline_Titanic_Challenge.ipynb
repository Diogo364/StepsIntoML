{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic Challenge - Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdFGx6M0U3vo0w1qXqwdDz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Diogo364/StepsIntoML/blob/master/Pipeline_Titanic_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLbV3zU4Q63L",
        "colab_type": "text"
      },
      "source": [
        "# Tutorial Sklearn Pipelines\n",
        "\n",
        "### Understanding Pipelines\n",
        "---\n",
        "[PT-BR]\n",
        "\n",
        "O uso de pipelines é muito comum para alcançar melhor reprodutibilidade de processos como limpeza e até predições utilizando Machine Learning.\n",
        "\n",
        "Para entender melhor o conceito de Pipeline aplicado a Machine Learning acesse o link em [português](https://docs.microsoft.com/pt-br/azure/machine-learning/concept-ml-pipelines).\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "It is very common the use o Pipelines to achieve better reproducibility of processes as cleanning and even predictions using ML.\n",
        "\n",
        "To understand better the concept of Machine Learning Pipelines check this [link](https://medium.com/analytics-vidhya/what-is-a-pipeline-in-machine-learning-how-to-create-one-bda91d0ceaca).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4e8pYLrSeQT",
        "colab_type": "text"
      },
      "source": [
        "## Basic Libraries\n",
        "---\n",
        "[PT-BR]\n",
        "\n",
        "Primeiramente iremos fazer a importação das bibliotecas clássicas de manipulação de dados do Python.\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "First, we will import the classic Python data manipulation libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UruyJGLjJL77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqer2F2GllXp",
        "colab_type": "text"
      },
      "source": [
        "## Import DataSet\n",
        "---\n",
        "\n",
        "[PT-BR]\n",
        "\n",
        "1.   Fazer download do [DataSet do Titanic no Kaggle](https://www.kaggle.com/c/titanic/data);\n",
        "2.   Subir os arquivos para o Colab;\n",
        "3.   Continuar o tutorial.\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "1.   Download [Titanic Dataset from Kaggle](https://www.kaggle.com/c/titanic/data) from the link;\n",
        "2.   Upload the files here;\n",
        "3.   Continue with the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5xaYCXLJ8TP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = pd.read_csv('train.csv')\n",
        "test_set = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7YfGr_yN_JW",
        "colab_type": "text"
      },
      "source": [
        "## Creating a Data Transformation Pipeline\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sn-Fdw0PQum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zncI1XU_dA1S",
        "colab_type": "text"
      },
      "source": [
        "## Bibliotecas Básicas\n",
        "---\n",
        "[PT-BR]\n",
        "\n",
        "Primeiro vamos definir a classe baseada na `BaseEstimator` para construir nossa própria transformação dos dados.\n",
        "\n",
        "Iremos utilizar o método `transformation` para:\n",
        "\n",
        " 1.   Criar a nova feature: `family`\n",
        " 2.   Remover as colunas `['Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'PassengerId']` \n",
        "\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "First we'll define a class based on `BaseEstimator` to make our own custom transformation on the data.\n",
        "\n",
        "We'll use the transformation method to:\n",
        "\n",
        " 1.   Create a new feature: `family`\n",
        " 2.   drop `['Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'PassengerId']` \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIx2bR-GUp0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TitanicFeatureEngeneering(BaseEstimator):\n",
        "  \n",
        "  def __init__(self):\n",
        "        pass\n",
        "\n",
        "  def fit(self, documents, y=None):\n",
        "      return self\n",
        "\n",
        "  def transform(self, x_dataset):\n",
        "      drop_columns = ['Name', 'Ticket', 'Cabin', 'SibSp', 'Parch', 'PassengerId']\n",
        "      x_dataset['family'] = x_dataset['SibSp'] + x_dataset['Parch']\n",
        "      transformed_dataset = x_dataset.drop(columns=drop_columns)\n",
        "      return transformed_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJQj4dlpdPCk",
        "colab_type": "text"
      },
      "source": [
        "### Dealing with missing values\n",
        "---\n",
        "[PT-BR]\n",
        "\n",
        "Usaremos duas abordagens diferentes dependendo do tipo do dado.\n",
        "\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "We'll use two different approachs depending on the type of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rku756cgdgiC",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Numerical\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MCPl87jhisP",
        "colab_type": "text"
      },
      "source": [
        "[PT-BR]\n",
        "\n",
        "Nossas Features numéricas são:\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "Our Numerical Features are:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ax0WOo9Bdixn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_features = ['Age', 'Fare', 'family']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5hBrKxwdsyT",
        "colab_type": "text"
      },
      "source": [
        "[PT-BR]\n",
        "\n",
        "Para lidar com os missing values nós iremos substituí-los pelo valor da mediana.\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "To deal with their missing values we'll simply replace them by the median value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmcvqdpKN-1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numeric_transformer = \\\n",
        "Pipeline(steps=[\n",
        "                ('imputer', SimpleImputer(strategy='median'))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUQjvnX2dzTU",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Categorical\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vYI9Q75huGP",
        "colab_type": "text"
      },
      "source": [
        "[PT-BR]\n",
        "\n",
        "Nossas Features categóricas são:\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "Our Categorical Features are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqES_WXweCfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_features = ['Embarked', 'Sex', 'Pclass']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tChOgYjAd1Ga",
        "colab_type": "text"
      },
      "source": [
        "[PT-BR]\n",
        "\n",
        "Para lidar com Features categóricas faremos assim?\n",
        "\n",
        "1.   Substituir os missing values pelo valor mais frequente;\n",
        "2.   Transformar as Features categóricas em numéricas utilizando `OneHotEncoder`\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "To deal with Categorical Features we'll do as following:\n",
        "\n",
        "1.   Replace missing values for the most frequent one\n",
        "2.   Transform our Categorical Features in Numerical Features using `OneHotEncoder`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOOLu4lUN-y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_transformer = \\\n",
        "Pipeline(steps=[\n",
        "                ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "                ('onehot', OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23FLurbVeTQt",
        "colab_type": "text"
      },
      "source": [
        "#### ColumnTransformer\n",
        "---\n",
        "\n",
        "[PT-BR]\n",
        "\n",
        "Para aplicar pipelines diferentes em features diferentes nós iremos utilizar a classe `ColumnTransformer`\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "To apply different pipelines on different features we'll use `ColumnTransformer` Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKZqcFcCN-wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lle0mZqre2Xs",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "[PT-BR]\n",
        "\n",
        "Finalmente, iremos finalizar nosso <b><u>Data Transformation Pipeline</u></b> juntando a classe `TitanicFeatureEngeneering` com as transformações de colunas do `preprocessor`\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "Then we'll finish our <b><u>Data Transformation Pipeline</u></b> gathering the `TitanicFeatureEngeneering` class that with our columns transformation from `preprocessor`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bX63JtDN-vO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformation_pipeline =\\\n",
        "Pipeline(steps=[\n",
        "                ('family', TitanicFeatureEngeneering()),\n",
        "                ('preprocessor', preprocessor),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzNSIw4b8G6Y",
        "colab_type": "text"
      },
      "source": [
        "## Creating a Machine Learning pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRCQTjT4kS-p",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "[PT-BR]\n",
        "\n",
        "Para essa parte nós juntaremos nosso Data Transformation Pipeline com o algoritmo do Scikitlearn - `RandomForestClassifier`  - usando os parametros abaixo:\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "For this part we'll gather our Data Transformation Pipeline with the Scikitlearn's `RandomForestClassifier` Algorithm using the following params:\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "  'max_depth': 6,\n",
        "  'min_samples_leaf': 1, \n",
        "  'min_samples_split': 4, \n",
        "  'random_state': 42\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLEXB7a4kAy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5XR42kpaRgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "machine_learning_pipeline =\\\n",
        "Pipeline(steps=[\n",
        "                ('datatransformation', transformation_pipeline),\n",
        "                ('machinelearning', RandomForestClassifier(max_depth=6, \n",
        "                                                           min_samples_leaf=1, \n",
        "                                                           min_samples_split=4, \n",
        "                                                           random_state=seed))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7H1ie63lYDN",
        "colab_type": "text"
      },
      "source": [
        "## Using our pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVPgYCSHlb0J",
        "colab_type": "text"
      },
      "source": [
        "### Data Transformation\n",
        "---\n",
        "\n",
        "\n",
        "[PT-BR]\n",
        "\n",
        "Primeiro iremos separar nossas features da nossa variável de interesse, então iremos ver nosso Data Transformation Pipeline funcionando.\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "First we'll split our features from our target, then we'll see our Data Transformation Pipeline working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRBNcB0ZmpZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_training = train_set.drop(columns='Survived')\n",
        "y_training = train_set['Survived']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sEfJrNQmaCs",
        "colab_type": "text"
      },
      "source": [
        "#### Original Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPA9fUwilfET",
        "colab_type": "code",
        "outputId": "d41b10f2-e668-40cb-b416-60ef336e5612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "x_training.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.28</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.92</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.10</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass  ... Cabin Embarked\n",
              "0            1       3  ...   NaN        S\n",
              "1            2       1  ...   C85        C\n",
              "2            3       3  ...   NaN        S\n",
              "3            4       1  ...  C123        S\n",
              "4            5       3  ...   NaN        S\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-T8n0mfmg30",
        "colab_type": "text"
      },
      "source": [
        "#### Transformed Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roeHW1K1md5C",
        "colab_type": "code",
        "outputId": "ea5fec77-b779-4641-9abe-e991a6e0607e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "transformation_pipeline.fit(x_training, y_training)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('family', TitanicFeatureEngeneering()),\n",
              "                ('preprocessor',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('num',\n",
              "                                                  Pipeline(memory=None,\n",
              "                                                           steps=[('imputer',\n",
              "                                                                   SimpleImputer(add_indicator=False,\n",
              "                                                                                 copy=True,\n",
              "                                                                                 fill_value=None,\n",
              "                                                                                 missing_values=nan,\n",
              "                                                                                 strategy='median',\n",
              "                                                                                 verbose=0))],\n",
              "                                                           verb...\n",
              "                                                  Pipeline(memory=None,\n",
              "                                                           steps=[('imputer',\n",
              "                                                                   SimpleImputer(add_indicator=False,\n",
              "                                                                                 copy=True,\n",
              "                                                                                 fill_value=None,\n",
              "                                                                                 missing_values=nan,\n",
              "                                                                                 strategy='most_frequent',\n",
              "                                                                                 verbose=0)),\n",
              "                                                                  ('onehot',\n",
              "                                                                   OneHotEncoder(categories='auto',\n",
              "                                                                                 drop=None,\n",
              "                                                                                 dtype=<class 'numpy.float64'>,\n",
              "                                                                                 handle_unknown='ignore',\n",
              "                                                                                 sparse=False))],\n",
              "                                                           verbose=False),\n",
              "                                                  ['Embarked', 'Sex',\n",
              "                                                   'Pclass'])],\n",
              "                                   verbose=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFvW8jgJnImt",
        "colab_type": "code",
        "outputId": "9eab7aae-1ff3-43e6-83da-e1429af15ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "transformed_data = transformation_pipeline.transform(x_training)\n",
        "transformed_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[22.    ,  7.25  ,  1.    , ...,  0.    ,  0.    ,  1.    ],\n",
              "       [38.    , 71.2833,  1.    , ...,  1.    ,  0.    ,  0.    ],\n",
              "       [26.    ,  7.925 ,  0.    , ...,  0.    ,  0.    ,  1.    ],\n",
              "       ...,\n",
              "       [28.    , 23.45  ,  3.    , ...,  0.    ,  0.    ,  1.    ],\n",
              "       [26.    , 30.    ,  0.    , ...,  1.    ,  0.    ,  0.    ],\n",
              "       [32.    ,  7.75  ,  0.    , ...,  0.    ,  0.    ,  1.    ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbtGlyz_ndSz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "[PT-BR]\n",
        "\n",
        "Embora o nome das colunas tenha desaparecido nós podemos comparar os dados das primeiras 3 colunas, que correspondem às nossas Features numéricas.\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "Even though the column names desappeared we can compare the data of the first 3 columns, that correspond to our Numeric Features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVH1XjTxnQt6",
        "colab_type": "code",
        "outputId": "125ecfb4-fd4b-4d97-db79-61ecf9c2ed08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "pd.DataFrame(transformed_data).head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.00</td>\n",
              "      <td>7.25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38.00</td>\n",
              "      <td>71.28</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26.00</td>\n",
              "      <td>7.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35.00</td>\n",
              "      <td>53.10</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.00</td>\n",
              "      <td>8.05</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0     1    2    3    4    5    6    7    8    9   10\n",
              "0 22.00  7.25 1.00 0.00 0.00 1.00 0.00 1.00 0.00 0.00 1.00\n",
              "1 38.00 71.28 1.00 1.00 0.00 0.00 1.00 0.00 1.00 0.00 0.00\n",
              "2 26.00  7.92 0.00 0.00 0.00 1.00 1.00 0.00 0.00 0.00 1.00\n",
              "3 35.00 53.10 1.00 0.00 0.00 1.00 1.00 0.00 1.00 0.00 0.00\n",
              "4 35.00  8.05 0.00 0.00 0.00 1.00 0.00 1.00 0.00 0.00 1.00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYyP4_7_n5Jo",
        "colab_type": "text"
      },
      "source": [
        "### Machine Learning\n",
        "---\n",
        "\n",
        "[PT-BR]\n",
        "\n",
        "Agora veremos o quão fácil é utilizar nosso Pipeline completo.\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "Now we'll see how easy it is to use our entire Pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnCd3702pAZc",
        "colab_type": "text"
      },
      "source": [
        "#### Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b1M9QGSn2ri",
        "colab_type": "code",
        "outputId": "1dc3c7a7-9b85-40a6-f194-2a5932bac63f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "machine_learning_pipeline.fit(x_training, y_training)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('datatransformation',\n",
              "                 Pipeline(memory=None,\n",
              "                          steps=[('family', TitanicFeatureEngeneering()),\n",
              "                                 ('preprocessor',\n",
              "                                  ColumnTransformer(n_jobs=None,\n",
              "                                                    remainder='drop',\n",
              "                                                    sparse_threshold=0.3,\n",
              "                                                    transformer_weights=None,\n",
              "                                                    transformers=[('num',\n",
              "                                                                   Pipeline(memory=None,\n",
              "                                                                            steps=[('imputer',\n",
              "                                                                                    SimpleImputer(add_indicator=False,\n",
              "                                                                                                  copy=True,\n",
              "                                                                                                  fill_value=None,\n",
              "                                                                                                  miss...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=6, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=4,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=42,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6tYg74rpKvv",
        "colab_type": "text"
      },
      "source": [
        "#### Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfnsKrAIpMQR",
        "colab_type": "code",
        "outputId": "30e496de-4ea7-40c7-ccf1-ad6d6a21616f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "machine_learning_pipeline.score(x_training, y_training)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.867564534231201"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1gXmgh8pHO_",
        "colab_type": "text"
      },
      "source": [
        "#### Predicting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhHHi99toalw",
        "colab_type": "code",
        "outputId": "d25caa1e-ff9a-4062-c9f5-681c72e46517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "predictions = machine_learning_pipeline.predict(test_set)\n",
        "predictions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoSvw-P9o1-0",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "[PT-BR]\n",
        "\n",
        "Pronto!\n",
        "\n",
        "Agora se quiser submeter ao leadeboard do Kaggle você precisa apenas juntar as predições com o `PassangersId` e fazer o Download do arquivo csv.\n",
        "\n",
        "[EN-US]\n",
        "\n",
        "Thats it! \n",
        "\n",
        "Now, if you want to submit to kaggle's leaderboard you just have to join our predictions with the `PassangersId` and Download the csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ1njSbHoyf_",
        "colab_type": "code",
        "outputId": "98316932-d5cb-4889-eb7e-c821443689fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "test_set['Survived'] = predictions\n",
        "submit_data = test_set[['PassengerId', 'Survived']]\n",
        "submit_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>1305</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1306</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>1307</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>1308</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>1309</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>418 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived\n",
              "0            892         0\n",
              "1            893         0\n",
              "2            894         0\n",
              "3            895         0\n",
              "4            896         1\n",
              "..           ...       ...\n",
              "413         1305         0\n",
              "414         1306         1\n",
              "415         1307         0\n",
              "416         1308         0\n",
              "417         1309         0\n",
              "\n",
              "[418 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HO-MVEcprpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_data.to_csv('survival_predictions.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}